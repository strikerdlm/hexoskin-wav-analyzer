#!/usr/bin/env python3
"""
Jupyter Environment Setup Script
For Valquiria Space Analog Simulation Data Analysis

This script sets up the Jupyter environment for working with the physiological data analysis notebooks.
"""

import subprocess
import sys
import os
from pathlib import Path

def run_command(command, description):
    """Run a command and handle errors."""
    print(f"\n{description}...")
    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        print(f"✓ {description} completed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"✗ Error in {description}: {e}")
        print(f"Error output: {e.stderr}")
        return False

def check_python_version():
    """Check if Python version is compatible."""
    version = sys.version_info
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("✗ Python 3.8 or higher is required")
        return False
    print(f"✓ Python {version.major}.{version.minor}.{version.micro} detected")
    return True

def install_requirements():
    """Install required packages."""
    requirements_file = Path(__file__).parent / "requirements_jupyter.txt"
    if not requirements_file.exists():
        print("✗ requirements_jupyter.txt not found")
        return False
    
    # Check if packages are already installed
    try:
        import pandas, numpy, matplotlib, seaborn, scipy, jupyter, ipykernel
        print("✓ Required packages already installed")
        return True
    except ImportError:
        return run_command(f"pip install -r {requirements_file}", "Installing Jupyter requirements")

def setup_jupyter_kernel():
    """Set up a Jupyter kernel for this project."""
    kernel_name = "valquiria-analysis"
    kernel_display_name = "Valquiria Space Analog Analysis"
    
    # Check if kernel already exists
    try:
        result = subprocess.run(f"jupyter kernelspec list", shell=True, capture_output=True, text=True)
        if kernel_name in result.stdout:
            print(f"✓ Kernel '{kernel_name}' already exists")
            return True
    except:
        pass
    
    # Create new kernel
    return run_command(f"python -m ipykernel install --user --name={kernel_name} --display-name='{kernel_display_name}'", 
                      f"Creating Jupyter kernel '{kernel_name}'")

def create_jupyter_config():
    """Create Jupyter configuration files."""
    config_dir = Path.home() / ".jupyter"
    config_dir.mkdir(exist_ok=True)
    
    # Create jupyter_notebook_config.py
    config_file = config_dir / "jupyter_notebook_config.py"
    if not config_file.exists():
        config_content = '''# Jupyter Notebook Configuration
# Generated by Valquiria setup script

c = get_config()

# Allow all origins (for local development)
c.NotebookApp.allow_origin = '*'

# Set the port
c.NotebookApp.port = 8888

# Allow root access (for local development)
c.NotebookApp.allow_root = True

# Set the notebook directory to the joined_data folder
import os
c.NotebookApp.notebook_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'Data', 'joined_data')

# Enable extensions
c.NotebookApp.enable_mathjax = True

# Set maximum file size for uploads (100MB)
c.NotebookApp.max_buffer_size = 104857600

print("Jupyter configuration loaded successfully")
'''
        with open(config_file, 'w') as f:
            f.write(config_content)
        print("✓ Created Jupyter configuration file")
    else:
        print("✓ Jupyter configuration file already exists")

def create_analysis_scripts():
    """Create helper scripts for data analysis."""
    scripts_dir = Path(__file__).parent / "scripts"
    scripts_dir.mkdir(exist_ok=True)
    
    # Create data loading script
    data_loader_script = scripts_dir / "load_data.py"
    if not data_loader_script.exists():
        loader_content = '''"""
Data Loading Utility for Valquiria Analysis
Provides functions to load and prepare data for analysis.
"""

import pandas as pd
import sqlite3
import os
from pathlib import Path

def load_csv_data():
    """Load all CSV files from the joined_data directory."""
    data_dir = Path(__file__).parent.parent
    csv_files = list(data_dir.glob("*.csv"))
    
    dataframes = {}
    for file in csv_files:
        try:
            df = pd.read_csv(file, low_memory=False)
            dataframes[file.stem] = df
            print(f"Loaded {file.name}: {len(df)} rows, {len(df.columns)} columns")
        except Exception as e:
            print(f"Error loading {file.name}: {e}")
    
    return dataframes

def load_database_data(db_path="merged_data.db"):
    """Load data from SQLite database."""
    data_dir = Path(__file__).parent.parent
    db_file = data_dir / db_path
    
    if not db_file.exists():
        print(f"Database file {db_file} not found")
        return None
    
    try:
        conn = sqlite3.connect(db_file)
        df = pd.read_sql_query("SELECT * FROM merged_data", conn)
        conn.close()
        print(f"Loaded database: {len(df)} rows, {len(df.columns)} columns")
        return df
    except Exception as e:
        print(f"Error loading database: {e}")
        return None

def get_data_summary(df):
    """Get a summary of the dataset."""
    if df is None:
        return "No data available"
    
    summary = {
        "rows": len(df),
        "columns": len(df.columns),
        "memory_usage": df.memory_usage(deep=True).sum() / 1024**2,  # MB
        "missing_values": df.isnull().sum().sum(),
        "duplicates": df.duplicated().sum()
    }
    
    return summary

if __name__ == "__main__":
    # Test data loading
    print("Testing data loading...")
    csv_data = load_csv_data()
    db_data = load_database_data()
    
    if db_data is not None:
        summary = get_data_summary(db_data)
        print(f"Database summary: {summary}")
'''
        with open(data_loader_script, 'w') as f:
            f.write(loader_content)
        print("✓ Created data loading script")
    
    # Create analysis utilities script
    analysis_utils_script = scripts_dir / "analysis_utils.py"
    if not analysis_utils_script.exists():
        utils_content = '''"""
Analysis Utilities for Valquiria Data
Common functions for statistical analysis and visualization.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import warnings
warnings.filterwarnings('ignore')

def setup_plotting_style():
    """Set up consistent plotting style for all visualizations."""
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    plt.rcParams['figure.figsize'] = (12, 8)
    plt.rcParams['font.size'] = 12
    plt.rcParams['axes.titlesize'] = 14
    plt.rcParams['axes.labelsize'] = 12

def analyze_variable_distribution(df, column, subject_col='subject'):
    """Analyze distribution of a variable across subjects."""
    setup_plotting_style()
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'Distribution Analysis: {column}', fontsize=16)
    
    # Overall histogram
    axes[0, 0].hist(df[column].dropna(), bins=50, alpha=0.7, edgecolor='black')
    axes[0, 0].set_title('Overall Distribution')
    axes[0, 0].set_xlabel(column)
    axes[0, 0].set_ylabel('Frequency')
    
    # Box plot by subject
    df.boxplot(column=column, by=subject_col, ax=axes[0, 1])
    axes[0, 1].set_title('Distribution by Subject')
    axes[0, 1].set_xlabel('Subject')
    axes[0, 1].set_ylabel(column)
    
    # Q-Q plot
    stats.probplot(df[column].dropna(), dist="norm", plot=axes[1, 0])
    axes[1, 0].set_title('Q-Q Plot (Normal Distribution)')
    
    # Descriptive statistics
    stats_text = df[column].describe().to_string()
    axes[1, 1].text(0.1, 0.5, stats_text, transform=axes[1, 1].transAxes, 
                    fontsize=10, verticalalignment='center',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
    axes[1, 1].set_title('Descriptive Statistics')
    axes[1, 1].axis('off')
    
    plt.tight_layout()
    plt.show()

def correlation_analysis(df, variables, method='pearson'):
    """Perform correlation analysis between variables."""
    # Calculate correlation matrix
    corr_matrix = df[variables].corr(method=method)
    
    # Create heatmap
    setup_plotting_style()
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                square=True, fmt='.3f')
    plt.title(f'{method.title()} Correlation Matrix')
    plt.tight_layout()
    plt.show()
    
    return corr_matrix

def time_series_analysis(df, variable, time_col='timestamp', subject_col='subject'):
    """Analyze time series patterns for a variable."""
    setup_plotting_style()
    
    # Convert time column if needed
    if df[time_col].dtype == 'object':
        df[time_col] = pd.to_datetime(df[time_col])
    
    # Plot time series by subject
    plt.figure(figsize=(15, 8))
    for subject in df[subject_col].unique():
        subject_data = df[df[subject_col] == subject]
        plt.plot(subject_data[time_col], subject_data[variable], 
                label=subject, alpha=0.7, linewidth=1)
    
    plt.title(f'Time Series: {variable}')
    plt.xlabel('Time')
    plt.ylabel(variable)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def statistical_comparison(df, variable, group_col='subject', test_type='kruskal'):
    """Perform statistical comparison between groups."""
    groups = [group for name, group in df.groupby(group_col)]
    
    if test_type == 'kruskal':
        statistic, p_value = stats.kruskal(*[group[variable].dropna() for group in groups])
        test_name = "Kruskal-Wallis H-test"
    elif test_type == 'anova':
        statistic, p_value = stats.f_oneway(*[group[variable].dropna() for group in groups])
        test_name = "One-way ANOVA"
    else:
        raise ValueError("test_type must be 'kruskal' or 'anova'")
    
    print(f"{test_name} Results:")
    print(f"Statistic: {statistic:.4f}")
    print(f"P-value: {p_value:.4e}")
    print(f"Significant: {'Yes' if p_value < 0.05 else 'No'}")
    
    return statistic, p_value

# Example usage functions
def quick_analysis(df, variables=['heart_rate [bpm]', 'breathing_rate [rpm]', 'activity [g]']):
    """Perform a quick analysis of key variables."""
    print("=== Quick Analysis Report ===")
    print(f"Dataset shape: {df.shape}")
    print(f"Variables analyzed: {variables}")
    
    for var in variables:
        if var in df.columns:
            print(f"\\n--- {var} ---")
            print(df[var].describe())
            
            # Distribution analysis
            analyze_variable_distribution(df, var)
            
            # Statistical comparison between subjects
            statistical_comparison(df, var)
        else:
            print(f"Variable {var} not found in dataset")

if __name__ == "__main__":
    print("Analysis utilities loaded successfully")
    print("Available functions:")
    print("- setup_plotting_style()")
    print("- analyze_variable_distribution(df, column)")
    print("- correlation_analysis(df, variables)")
    print("- time_series_analysis(df, variable)")
    print("- statistical_comparison(df, variable)")
    print("- quick_analysis(df, variables)")
'''
        with open(analysis_utils_script, 'w') as f:
            f.write(utils_content)
        print("✓ Created analysis utilities script")

def main():
    """Main setup function."""
    print("=" * 60)
    print("Jupyter Environment Setup for Valquiria Analysis")
    print("=" * 60)
    
    # Check Python version
    if not check_python_version():
        sys.exit(1)
    
    # Install requirements
    if not install_requirements():
        print("✗ Failed to install requirements")
        sys.exit(1)
    
    # Setup Jupyter kernel
    if not setup_jupyter_kernel():
        print("✗ Failed to setup Jupyter kernel")
        sys.exit(1)
    
    # Create Jupyter configuration
    create_jupyter_config()
    
    # Create analysis scripts
    create_analysis_scripts()
    
    print("\n" + "=" * 60)
    print("✓ Setup completed successfully!")
    print("=" * 60)
    print("\nNext steps:")
    print("1. Start Jupyter: jupyter notebook")
    print("2. Or start JupyterLab: jupyter lab")
    print("3. Select the 'Valquiria Space Analog Analysis' kernel")
    print("4. Open Results.ipynb or Results_2.ipynb")
    print("\nHelper scripts available in the 'scripts' folder:")
    print("- load_data.py: Data loading utilities")
    print("- analysis_utils.py: Common analysis functions")

if __name__ == "__main__":
    main() 